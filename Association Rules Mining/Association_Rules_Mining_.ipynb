{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a0a0506"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colab-samples/blob/main/notebooks/basic_notebook_features/text_cells.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -U pip setuptools wheel scikit-learn>=1.4 -q\n",
        "!pip install -U git+https://github.com/pycaret/pycaret.git@master -q\n",
        "!pip install mlxtend gradio -q\n",
        "print(\"‚úÖ All libraries installed!\")"
      ],
      "metadata": {
        "id": "j7AlYpM_C-Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load Online Retail dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
        "data = pd.read_excel(url)\n",
        "\n",
        "print(f\"‚úÖ Online Retail Dataset loaded: {data.shape}\")\n",
        "print(f\"\\nColumns: {list(data.columns)}\")\n",
        "print(f\"\\nSample transactions:\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "btD_swp8C-HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the dataset\n",
        "print(\"üßπ Cleaning data...\")\n",
        "\n",
        "# Remove missing values\n",
        "data = data.dropna(subset=['InvoiceNo', 'Description', 'CustomerID'])\n",
        "\n",
        "# Remove cancelled orders (InvoiceNo starting with 'C')\n",
        "data = data[~data['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "\n",
        "# Keep only positive quantities and prices\n",
        "data = data[(data['Quantity'] > 0) & (data['UnitPrice'] > 0)]\n",
        "\n",
        "# Remove generic descriptions\n",
        "data = data[~data['Description'].str.contains('POSTAGE|DISCOUNT|SAMPLE|TEST', case=False, na=False)]\n",
        "\n",
        "print(f\"‚úÖ Cleaned data: {data.shape}\")\n",
        "print(f\"Unique products: {data['Description'].nunique()}\")\n",
        "print(f\"Unique transactions: {data['InvoiceNo'].nunique()}\")"
      ],
      "metadata": {
        "id": "-uOgzvWLC-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Create basket: transactions x products matrix\n",
        "basket = (data\n",
        "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
        "          .sum()\n",
        "          .unstack()\n",
        "          .reset_index()\n",
        "          .fillna(0)\n",
        "          .set_index('InvoiceNo'))\n",
        "\n",
        "# Convert to binary (1 if purchased, 0 otherwise)\n",
        "basket_binary = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "print(f\"‚úÖ Basket matrix created: {basket_binary.shape}\")\n",
        "print(f\"   Transactions: {basket_binary.shape[0]}\")\n",
        "print(f\"   Products: {basket_binary.shape[1]}\")\n",
        "print(f\"\\nSample basket:\")\n",
        "basket_binary.head()"
      ],
      "metadata": {
        "id": "sh9N7HZaC-Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find frequent itemsets using Apriori algorithm\n",
        "print(\"‚õèÔ∏è Mining frequent itemsets...\")\n",
        "min_support = 0.02  # 2% minimum support\n",
        "\n",
        "frequent_itemsets = apriori(basket_binary,\n",
        "                             min_support=min_support,\n",
        "                             use_colnames=True,\n",
        "                             max_len=3)\n",
        "\n",
        "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
        "\n",
        "print(f\"‚úÖ Found {len(frequent_itemsets)} frequent itemsets\")\n",
        "print(f\"\\nItemset size distribution:\")\n",
        "print(frequent_itemsets['length'].value_counts().sort_index())\n",
        "print(f\"\\nTop 10 frequent itemsets:\")\n",
        "frequent_itemsets.sort_values('support', ascending=False).head(10)"
      ],
      "metadata": {
        "id": "T546g-73C9_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate association rules\n",
        "print(\"üìã Generating association rules...\")\n",
        "\n",
        "rules = association_rules(frequent_itemsets,\n",
        "                          metric=\"confidence\",\n",
        "                          min_threshold=0.3)\n",
        "\n",
        "# Add lift filtering\n",
        "rules = rules[rules['lift'] > 1]\n",
        "\n",
        "# Sort by lift (most interesting rules first)\n",
        "rules = rules.sort_values('lift', ascending=False)\n",
        "\n",
        "print(f\"‚úÖ Generated {len(rules)} association rules\")\n",
        "print(f\"\\nTop 10 rules by lift:\")\n",
        "rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)"
      ],
      "metadata": {
        "id": "pOLUiMR8C99l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Support vs Confidence colored by Lift\n",
        "scatter = axes[0].scatter(rules['support'], rules['confidence'],\n",
        "                          c=rules['lift'], cmap='viridis',\n",
        "                          alpha=0.6, s=50)\n",
        "axes[0].set_xlabel('Support', fontsize=12)\n",
        "axes[0].set_ylabel('Confidence', fontsize=12)\n",
        "axes[0].set_title('Support vs Confidence (colored by Lift)', fontsize=14)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter, ax=axes[0], label='Lift')\n",
        "\n",
        "# Plot 2: Lift Distribution\n",
        "axes[1].hist(rules['lift'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "axes[1].set_xlabel('Lift', fontsize=12)\n",
        "axes[1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1].set_title('Distribution of Lift Values', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìä Visualization complete!\")"
      ],
      "metadata": {
        "id": "fNmvP47YC97Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze top rules in detail\n",
        "print(\"üîç Top 5 Association Rules:\\n\")\n",
        "\n",
        "for idx, rule in rules.head(5).iterrows():\n",
        "    antecedents = ', '.join(list(rule['antecedents']))\n",
        "    consequents = ', '.join(list(rule['consequents']))\n",
        "\n",
        "    print(f\"Rule {idx + 1}:\")\n",
        "    print(f\"  IF customer buys: {antecedents}\")\n",
        "    print(f\"  THEN they also buy: {consequents}\")\n",
        "    print(f\"  Support: {rule['support']:.3f} | Confidence: {rule['confidence']:.3f} | Lift: {rule['lift']:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "l2V0ewXPC94x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save association rules\n",
        "output_file = 'online_retail_association_rules.csv'\n",
        "rules.to_csv(output_file, index=False)\n",
        "print(f\"üíæ Rules saved to {output_file}\")\n",
        "\n",
        "print(f\"\\nüìä Summary Statistics:\")\n",
        "print(f\"   ‚Ä¢ Total Rules: {len(rules)}\")\n",
        "print(f\"   ‚Ä¢ Average Confidence: {rules['confidence'].mean():.2%}\")\n",
        "print(f\"   ‚Ä¢ Average Lift: {rules['lift'].mean():.2f}\")\n",
        "print(f\"   ‚Ä¢ Max Lift: {rules['lift'].max():.2f}\")"
      ],
      "metadata": {
        "id": "ud7TlSR7C91_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Prepare recommendation function\n",
        "def recommend_products(product_name):\n",
        "    \"\"\"Recommend products based on association rules\"\"\"\n",
        "\n",
        "    # Find rules where the product is in antecedents\n",
        "    matching_rules = rules[rules['antecedents'].apply(\n",
        "        lambda x: product_name.upper() in [item.upper() for item in x]\n",
        "    )]\n",
        "\n",
        "    if len(matching_rules) == 0:\n",
        "        return \"No recommendations found for this product. Try another product!\"\n",
        "\n",
        "    # Get top 5 recommendations\n",
        "    top_recommendations = matching_rules.nlargest(5, 'lift')\n",
        "\n",
        "    result = f\"üõí **Recommendations for: {product_name}**\\n\\n\"\n",
        "\n",
        "    for idx, (_, rule) in enumerate(top_recommendations.iterrows(), 1):\n",
        "        consequents = ', '.join(list(rule['consequents']))\n",
        "        result += f\"{idx}. **{consequents}**\\n\"\n",
        "        result += f\"   Confidence: {rule['confidence']:.1%} | Lift: {rule['lift']:.2f}\\n\\n\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Get list of products for dropdown\n",
        "product_list = sorted(data['Description'].unique()[:100])  # Top 100 products\n",
        "\n",
        "# Create Gradio interface\n",
        "demo1 = gr.Interface(\n",
        "    fn=recommend_products,\n",
        "    inputs=gr.Dropdown(choices=product_list, label=\"Select a Product\"),\n",
        "    outputs=gr.Textbox(label=\"Recommended Products\", lines=10),\n",
        "    title=\"üõçÔ∏è Product Recommendation System\",\n",
        "    description=\"Select a product to see what customers typically buy together!\",\n",
        "    examples=[product_list[0], product_list[10], product_list[20]]\n",
        ")\n",
        "\n",
        "demo1.launch(share=True)"
      ],
      "metadata": {
        "id": "0ZWYtHuyDXMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def analyze_basket(products_str):\n",
        "    \"\"\"Analyze a shopping basket and suggest additional items\"\"\"\n",
        "\n",
        "    # Parse input products\n",
        "    products = [p.strip().upper() for p in products_str.split(',')]\n",
        "\n",
        "    if len(products) == 0:\n",
        "        return \"Please enter at least one product!\"\n",
        "\n",
        "    # Find rules where ANY of the input products are antecedents\n",
        "    matching_rules = rules[rules['antecedents'].apply(\n",
        "        lambda x: any(prod in [item.upper() for item in x] for prod in products)\n",
        "    )]\n",
        "\n",
        "    if len(matching_rules) == 0:\n",
        "        return \"No suggestions found for these products.\"\n",
        "\n",
        "    # Get top suggestions\n",
        "    top_suggestions = matching_rules.nlargest(10, 'lift')\n",
        "\n",
        "    # Remove products already in basket\n",
        "    top_suggestions = top_suggestions[~top_suggestions['consequents'].apply(\n",
        "        lambda x: any(prod in [item.upper() for item in x] for prod in products)\n",
        "    )]\n",
        "\n",
        "    result = f\"üõí **Your Basket:** {', '.join(products)}\\n\\n\"\n",
        "    result += f\"üí° **Suggested Add-ons:**\\n\\n\"\n",
        "\n",
        "    for idx, (_, rule) in enumerate(top_suggestions.head(5).iterrows(), 1):\n",
        "        consequents = ', '.join(list(rule['consequents']))\n",
        "        antecedents = ', '.join(list(rule['antecedents']))\n",
        "        result += f\"{idx}. **{consequents}**\\n\"\n",
        "        result += f\"   Based on: {antecedents}\\n\"\n",
        "        result += f\"   {rule['confidence']:.1%} of customers who bought these also bought this\\n\"\n",
        "        result += f\"   Lift: {rule['lift']:.2f}x more likely\\n\\n\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Create Gradio interface\n",
        "demo2 = gr.Interface(\n",
        "    fn=analyze_basket,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"Enter products in your basket (comma-separated)\",\n",
        "        placeholder=\"e.g., WHITE HANGING HEART T-LIGHT HOLDER, REGENCY CAKESTAND 3 TIER\",\n",
        "        lines=3\n",
        "    ),\n",
        "    outputs=gr.Textbox(label=\"Smart Suggestions\", lines=15),\n",
        "    title=\"üß∫ Smart Basket Analyzer\",\n",
        "    description=\"Enter products you're buying and get intelligent cross-sell suggestions based on real purchase patterns!\",\n",
        "    examples=[\n",
        "        \"WHITE HANGING HEART T-LIGHT HOLDER\",\n",
        "        \"REGENCY CAKESTAND 3 TIER, PINK REGENCY TEACUP AND SAUCER\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "demo2.launch(share=True)"
      ],
      "metadata": {
        "id": "U1J5aqLsDXHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}